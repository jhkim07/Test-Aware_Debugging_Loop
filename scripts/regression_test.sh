#!/bin/bash
# íšŒê·€ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ - P0 ê°œì„ ì‚¬í•­ì´ ê¸°ì¡´ ì„±ê³µ ì¼€ì´ìŠ¤ë¥¼ ë³´í˜¸í•˜ëŠ”ì§€ ê²€ì¦
# Usage: ./scripts/regression_test.sh

set -e

# Set PYTHONPATH
export PYTHONPATH=/home/jin/prj_ws/agenticAI/Test-Aware_Debugging_Loop:$PYTHONPATH

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
CYAN='\033[0;36m'
NC='\033[0m'

echo -e "${CYAN}========================================${NC}"
echo -e "${CYAN}íšŒê·€ í…ŒìŠ¤íŠ¸ (Regression Test)${NC}"
echo -e "${CYAN}P0 ê°œì„ ì‚¬í•­ ì•ˆì „ì„± ê²€ì¦${NC}"
echo -e "${CYAN}========================================${NC}"
echo ""

# Phase 1: ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
echo -e "${CYAN}[Phase 1/3] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰...${NC}"
echo ""

# Test 1: diff_validator context ê³„ì‚°
echo -e "${YELLOW}Test 1: diff_validator context calculation${NC}"
python3 << 'EOF'
from bench_agent.protocol.diff_validator import _calculate_actual_hunk_counts

# Test case 1: astropy-12907 ìœ ì‚¬ íŒ¨ì¹˜ (ê°„ë‹¨í•œ 1ì¤„ ë³€ê²½)
diff_lines = [
    '@@ -242,5 +242,5 @@',
    '         cright = _coord_matrix(right, "right", noutp)',
    '     else:',
    '         cright = np.zeros((noutp, right.shape[1]))',
    '-        cright[-right.shape[0]:, -right.shape[1]:] = 1',
    '+        cright[-right.shape[0]:, -right.shape[1]:] = right',
    '',
    '     return np.hstack([cleft, cright])'
]

old_count, new_count = _calculate_actual_hunk_counts(diff_lines, 0)
print(f"  Result: old_count={old_count}, new_count={new_count}")

# ì˜ˆìƒ: 1 removed + 4 context = 5, 1 added + 4 context = 5
if old_count == 5 and new_count == 5:
    print("  âœ… PASS: Correct count (5, 5)")
else:
    print(f"  âŒ FAIL: Expected (5, 5), got ({old_count}, {new_count})")
    exit(1)

# Test case 2: ë¹ˆ ì¤„ í¬í•¨ ì¼€ì´ìŠ¤
diff_lines_with_empty = [
    '@@ -10,7 +10,8 @@',
    ' line 1',
    ' ',  # ë¹ˆ ì¤„ (context)
    ' line 3',
    '-old line',
    '+new line 1',
    '+new line 2',
    ' ',  # ë¹ˆ ì¤„ (context)
    ' line 6'
]

old_count, new_count = _calculate_actual_hunk_counts(diff_lines_with_empty, 0)
print(f"  Result (with empty lines): old_count={old_count}, new_count={new_count}")

# ì˜ˆìƒ: 1 removed + 5 context (ë¹ˆ ì¤„ 2ê°œ í¬í•¨) = 6, 2 added + 5 context = 7
# Context: ' line 1', ' ' (empty), ' line 3', ' ' (empty), ' line 6' = 5
expected_old = 6
expected_new = 7
if old_count == expected_old and new_count == expected_new:
    print(f"  âœ… PASS: Correctly counts empty lines ({expected_old}, {expected_new})")
else:
    print(f"  âŒ FAIL: Expected ({expected_old}, {expected_new}), got ({old_count}, {new_count})")
    exit(1)

print("")
EOF

# Test 2: llm_client temperature ê¸°ë³¸ê°’
echo -e "${YELLOW}Test 2: llm_client temperature default${NC}"
python3 << 'EOF'
import inspect
from bench_agent.agent.llm_client import chat

# Check function signature
sig = inspect.signature(chat)
temp_param = sig.parameters['temperature']
default_temp = temp_param.default

print(f"  Default temperature: {default_temp}")

if default_temp == 0.0:
    print("  âœ… PASS: Temperature defaults to 0.0 (deterministic)")
else:
    print(f"  âŒ FAIL: Expected temperature=0.0, got {default_temp}")
    exit(1)

print("")
EOF

# Test 3: reference_test_analyzer ì¶”ì¶œ
echo -e "${YELLOW}Test 3: reference_test_analyzer expected value extraction${NC}"
python3 << 'EOF'
from bench_agent.protocol.reference_test_analyzer import analyze_reference_test_patch

# astropy-12907 ìœ ì‚¬ test patch
test_patch = """diff --git a/test_file.py b/test_file.py
--- a/test_file.py
+++ b/test_file.py
@@ -1,3 +1,8 @@
 p1 = models.Polynomial1D(1, name='p1')

+cm_4d_expected = (np.array([False, False, True, True]),
+                  np.array([[True,  True,  False, False],
+                            [True,  True,  False, False]]))
+
 compound_models = {
+    'cm8': (rot & (sh1 & sh2), cm_4d_expected),
 }
"""

result = analyze_reference_test_patch(test_patch)
expected_values = result.get('expected_values', {})

print(f"  Extracted expected values: {list(expected_values.keys())}")

if 'cm_4d_expected' in expected_values:
    print("  âœ… PASS: Expected value 'cm_4d_expected' extracted")
else:
    print(f"  âŒ FAIL: Expected value not extracted. Got: {expected_values}")
    exit(1)

# Check hints generation
hints = result.get('expected_value_hints', '')
if 'CRITICAL' in hints and 'cm_4d_expected' in hints:
    print("  âœ… PASS: Expected value hints generated")
else:
    print(f"  âŒ FAIL: Hints not properly generated")
    exit(1)

print("")
EOF

# Test 4: patch_fallback ì‹¤íŒ¨ ê°ì§€
echo -e "${YELLOW}Test 4: patch_fallback failure detection${NC}"
python3 << 'EOF'
from bench_agent.protocol.patch_fallback import extract_patch_failure_details

# Test case 1: Hunk failure (astropy-14182 íŒ¨í„´)
stderr1 = """
patching file astropy/io/ascii/rst.py
Hunk #1 FAILED at 27.
1 out of 1 hunk FAILED -- saving rejects to file astropy/io/ascii/rst.py.rej
"""

result1 = extract_patch_failure_details(stderr1, "")
print(f"  Test 'Hunk FAILED': {result1}")

if result1['failed'] and result1['failure_type'] == 'line_mismatch':
    print("  âœ… PASS: Hunk failure detected correctly")
else:
    print(f"  âŒ FAIL: Expected line_mismatch failure, got {result1}")
    exit(1)

# Test case 2: ì„±ê³µ ì¼€ì´ìŠ¤ (false positive ì—†ì–´ì•¼ í•¨)
stdout2 = "patching file test.py\nSuccessfully applied patch"
result2 = extract_patch_failure_details("", stdout2)

if not result2['failed']:
    print("  âœ… PASS: No false positive on successful patch")
else:
    print(f"  âŒ FAIL: False positive detected: {result2}")
    exit(1)

print("")
EOF

echo -e "${GREEN}âœ… Phase 1 ì™„ë£Œ: ëª¨ë“  ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ í†µê³¼${NC}"
echo ""

# Phase 2: í†µí•© í…ŒìŠ¤íŠ¸ (ê¸°ì¡´ ì„±ê³µ ì¼€ì´ìŠ¤ ë³´í˜¸)
echo -e "${CYAN}[Phase 2/3] í†µí•© í…ŒìŠ¤íŠ¸ - ê¸°ì¡´ ì„±ê³µ ì¼€ì´ìŠ¤ ë³´í˜¸ ê²€ì¦${NC}"
echo ""

# Check if OPENAI_API_KEY is set
if [ -z "$OPENAI_API_KEY" ]; then
    echo -e "${YELLOW}âš ï¸  OPENAI_API_KEY not set. Skipping integration tests.${NC}"
    echo -e "${YELLOW}    Set API key to run full regression test:${NC}"
    echo -e "${YELLOW}    export OPENAI_API_KEY='your-key'${NC}"
    echo ""
else
    echo -e "${YELLOW}Running astropy__astropy-12907 (ê¸°ì¡´ ì„±ê³µ ì¼€ì´ìŠ¤)...${NC}"
    echo -e "${YELLOW}This will take 10-20 minutes...${NC}"
    echo ""

    RUN_ID="regression-$(date +%Y%m%d-%H%M%S)"

    python3 scripts/run_mvp.py \
        --config configs/mvp.yaml \
        --run-id ${RUN_ID} \
        --max-workers 1 \
        --instance-ids astropy__astropy-12907

    # ê²°ê³¼ ë¹„êµ
    echo ""
    echo -e "${CYAN}ê²°ê³¼ ë¹„êµ ì¤‘...${NC}"

    python3 << EOF
import json
from pathlib import Path

# ê¸°ì¡´ ê²°ê³¼ (baseline)
baseline_path = Path('outputs/mvp-20251215-013151/astropy__astropy-12907/metrics.json')
if not baseline_path.exists():
    print("âš ï¸  Baseline metrics not found. Skipping comparison.")
    print(f"   Expected: {baseline_path}")
    exit(0)

old_metrics = json.loads(baseline_path.read_text())

# ìƒˆ ê²°ê³¼
new_path = Path('outputs/${RUN_ID}/astropy__astropy-12907/metrics.json')
if not new_path.exists():
    print("âŒ New metrics not found!")
    exit(1)

new_metrics = json.loads(new_path.read_text())

print("=" * 60)
print("íšŒê·€ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¹„êµ")
print("=" * 60)
print(f"{'ë©”íŠ¸ë¦­':<20} {'ê¸°ì¡´':<15} {'P0 ê°œì„  í›„':<15} {'ìƒíƒœ':<10}")
print("-" * 60)

# Overall Score
old_overall = old_metrics['scores']['overall']
new_overall = new_metrics['scores']['overall']
overall_status = "âœ… PASS" if new_overall >= old_overall * 0.99 else "âŒ FAIL"
print(f"{'Overall Score':<20} {old_overall:<15.4f} {new_overall:<15.4f} {overall_status:<10}")

# BRS
old_brs = old_metrics['scores']['brs']
new_brs = new_metrics['scores']['brs']
brs_status = "âœ… PASS" if new_brs == 1.0 else "âŒ FAIL"
print(f"{'BRS':<20} {old_brs:<15.1f} {new_brs:<15.1f} {brs_status:<10}")

# Iterations
old_iter = old_metrics['iterations']
new_iter = new_metrics['iterations']
iter_status = "âœ… PASS" if new_iter <= old_iter else "âš ï¸  WARN"
print(f"{'Iterations':<20} {old_iter:<15} {new_iter:<15} {iter_status:<10}")

# Public/Hidden Pass Rate
old_public = old_metrics['final_iteration']['public_pass_rate']
new_public = new_metrics['final_iteration']['public_pass_rate']
public_status = "âœ… PASS" if new_public >= old_public else "âŒ FAIL"
print(f"{'Public Pass Rate':<20} {old_public:<15.2%} {new_public:<15.2%} {public_status:<10}")

old_hidden = old_metrics['final_iteration']['hidden_pass_rate']
new_hidden = new_metrics['final_iteration']['hidden_pass_rate']
hidden_status = "âœ… PASS" if new_hidden >= old_hidden else "âŒ FAIL"
print(f"{'Hidden Pass Rate':<20} {old_hidden:<15.2%} {new_hidden:<15.2%} {hidden_status:<10}")

print("=" * 60)

# ìµœì¢… íŒì •
regression = (
    new_overall < old_overall * 0.99 or
    new_brs < 1.0 or
    new_public < old_public or
    new_hidden < old_hidden
)

if regression:
    print("âŒ íšŒê·€ ë°œìƒ! ê¸°ì¡´ ì„±ê³µ ì¼€ì´ìŠ¤ê°€ ì €í•˜ë˜ì—ˆìŠµë‹ˆë‹¤.")
    exit(1)
else:
    print("âœ… íšŒê·€ ì—†ìŒ! ê¸°ì¡´ ì„±ê³µ ì¼€ì´ìŠ¤ê°€ ë³´í˜¸ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # ê°œì„  ì‚¬í•­ ì²´í¬
    improvements = []
    if new_overall > old_overall:
        improvements.append(f"  â€¢ Overall Score í–¥ìƒ: {old_overall:.4f} â†’ {new_overall:.4f}")
    if new_iter < old_iter:
        improvements.append(f"  â€¢ Iterations ê°ì†Œ: {old_iter} â†’ {new_iter}")

    if improvements:
        print("\nğŸ‰ ì¶”ê°€ ê°œì„  ì‚¬í•­:")
        for imp in improvements:
            print(imp)

EOF

    if [ $? -eq 0 ]; then
        echo ""
        echo -e "${GREEN}âœ… Phase 2 ì™„ë£Œ: ê¸°ì¡´ ì„±ê³µ ì¼€ì´ìŠ¤ ë³´í˜¸ í™•ì¸ë¨${NC}"
    else
        echo ""
        echo -e "${RED}âŒ Phase 2 ì‹¤íŒ¨: íšŒê·€ ë°œìƒ${NC}"
        exit 1
    fi
fi

echo ""

# Phase 3: ìš”ì•½
echo -e "${CYAN}[Phase 3/3] ìµœì¢… ìš”ì•½${NC}"
echo ""

echo -e "${GREEN}========================================${NC}"
echo -e "${GREEN}íšŒê·€ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!${NC}"
echo -e "${GREEN}========================================${NC}"
echo ""

echo "âœ… ê²€ì¦ëœ ì‚¬í•­:"
echo "  1. diff_validator - context ê³„ì‚° ë¡œì§ ì •í™•ì„±"
echo "  2. llm_client - temperature=0 ê¸°ë³¸ê°’ ì„¤ì •"
echo "  3. reference_test_analyzer - expected value ì¶”ì¶œ"
echo "  4. patch_fallback - ì‹¤íŒ¨ ê°ì§€ ì •í™•ì„±"

if [ -n "$OPENAI_API_KEY" ]; then
    echo "  5. ê¸°ì¡´ ì„±ê³µ ì¼€ì´ìŠ¤ (astropy-12907) ë³´í˜¸"
fi

echo ""
echo -e "${CYAN}ë‹¤ìŒ ë‹¨ê³„:${NC}"
echo "1. ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ê°œì„  í™•ì¸:"
echo "   ./scripts/test_p0_improvements.sh astropy__astropy-14182"
echo ""
echo "2. ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰:"
echo "   python scripts/run_mvp.py --config configs/mvp.yaml --run-id p0-full-test"
echo ""
echo "3. ì„±ëŠ¥ ë¶„ì„:"
echo "   python scripts/analyze_performance.py p0-full-test"
echo ""

echo -e "${GREEN}íšŒê·€ í…ŒìŠ¤íŠ¸ ì„±ê³µ! P0 ê°œì„ ì‚¬í•­ì´ ì•ˆì „í•©ë‹ˆë‹¤.${NC}"
