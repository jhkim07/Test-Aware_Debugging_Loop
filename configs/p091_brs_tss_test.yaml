# Component 3 - BRS/TSS Measurement Test
# Phase: Performance validation with baseline comparison
# Purpose: Measure BRS/TSS/COMB scores and compare to Phase 0.9.1

runner:
  dataset_name: "princeton-nlp/SWE-bench_Lite"

instances:
  list:
    # Phase 0.9.1 Verified Baseline (4 instances)
    # We know exact BRS/TSS/COMB scores for these
    - "astropy__astropy-12907"   # Baseline: BRS=1.0, TSS=1.0, Overall=0.987
    - "sympy__sympy-20590"       # Baseline: BRS=1.0, TSS=1.0, Overall=0.994
    - "astropy__astropy-14182"   # Baseline: BRS=1.0, TSS=0.5, Overall=0.825
    - "astropy__astropy-14365"   # Baseline: BRS=1.0, TSS=1.0, Overall=0.994

    # Additional SWE-bench Lite instances (commonly used, likely to work)
    # Selected based on: popularity, project diversity, expected success
    - "astropy__astropy-6938"    # Astropy - similar to verified
    - "astropy__astropy-7746"    # Astropy - similar to verified
    - "sympy__sympy-13043"       # Sympy - similar to verified
    - "sympy__sympy-13471"       # Sympy - similar to verified
    - "sympy__sympy-13177"       # Sympy - similar to verified
    - "sympy__sympy-13480"       # Sympy - similar to verified
    - "astropy__astropy-7336"    # Astropy - additional
    - "sympy__sympy-12481"       # Sympy - additional
    - "sympy__sympy-13915"       # Sympy - additional
    - "astropy__astropy-8005"    # Astropy - additional
    - "sympy__sympy-11400"       # Sympy - additional

limits:
  max_iters: 8
  time_limit_minutes: 120

split:
  public_ratio: 0.7
  seed: 0

policy:
  forbid_skip: true
  forbid_xfail: true
  forbid_network: true
  restrict_file_io: true

llm:
  enabled: true
  model: "gpt-4o"

# Component 3: Edit Script Mode
edit_script:
  enabled: true
  require_unique_anchors: true
  max_candidates_per_type: 20
  use_ranked_candidates: true
